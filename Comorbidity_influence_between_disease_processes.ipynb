{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPcmXVGpsK5Dc+dLB42Igy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrRiteshAjoodha/CV-of-Dr.-Ritesh-Ajoodha/blob/master/Comorbidity_influence_between_disease_processes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cm7-PSKwHgzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8fe1b6-75da-4f1d-ed61-ca1a2b286f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Summary ===\n",
            "Independent BIC: -63834.04695506026\n",
            "Influence   BIC: -63559.41164167458\n",
            "\n",
            "Edges learned (influence model):\n",
            "  diab_t -> diab_t1\n",
            "  ckd_t -> ckd_t1\n",
            "  htn_t -> htn_t1\n",
            "  bp_t -> bp_t1\n",
            "  hba1c_t -> hba1c_t1\n",
            "  creat_t -> creat_t1\n",
            "  diab_t -> hba1c_t1\n",
            "  htn_t -> bp_t1\n",
            "  ckd_t -> creat_t1\n",
            "\n",
            "Per-variable next-step accuracy (independent):\n",
            "  diab: 0.734\n",
            "  ckd: 0.779\n",
            "  htn: 0.739\n",
            "  bp: 0.754\n",
            "  hba1c: 0.746\n",
            "  creat: 0.795\n",
            "Per-variable next-step accuracy (influence):\n",
            "  diab: 0.734\n",
            "  ckd: 0.779\n",
            "  htn: 0.739\n",
            "  bp: 0.761\n",
            "  hba1c: 0.767\n",
            "  creat: 0.799\n",
            "\n",
            "Saved: run_report.json\n"
          ]
        }
      ],
      "source": [
        "# === One-cell Colab script with safe setup + auto-restart ===\n",
        "import sys, os, subprocess, json, datetime\n",
        "\n",
        "def need_setup():\n",
        "    try:\n",
        "        import numpy as np\n",
        "        import sklearn\n",
        "        return not (int(np.__version__.split('.')[0]) >= 2 and int(sklearn.__version__.split('.')[0]) >= 1 and int(sklearn.__version__.split('.')[1]) >= 6)\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "if need_setup():\n",
        "    print(\"ðŸ”§ Setting up compatible versions (NumPy â‰¥2, scikit-learn â‰¥1.6, pgmpy) ...\")\n",
        "    # Pin to versions that play nicely in current Colab images\n",
        "    cmds = [\n",
        "        \"pip\", \"install\", \"-q\", \"--upgrade\",\n",
        "        \"numpy>=2.0.0\",\n",
        "        \"pandas>=2.2.2\",\n",
        "        \"scikit-learn>=1.6.0\",\n",
        "        \"networkx>=3.2.1\",\n",
        "        \"matplotlib>=3.8.4\",\n",
        "        \"pgmpy==0.1.25\"\n",
        "    ]\n",
        "    subprocess.check_call([sys.executable, \"-m\"] + cmds)\n",
        "    print(\"âœ… Setup complete. The runtime will restart once to load new NumPy. Please re-run this cell afterwards.\")\n",
        "    # Force a runtime restart to avoid binary incompatibility\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "# ----------------- Everything below runs AFTER restart -----------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Tuple, Dict\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import BicScore, MaximumLikelihoodEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --------- Synthetic data generator ---------\n",
        "def _clip_state(x, k):\n",
        "    return int(max(0, min(k - 1, x)))\n",
        "\n",
        "def generate_synthetic_comorbidity(n_patients=300, timesteps=20, random_state=42, K=3):\n",
        "    \"\"\"\n",
        "    3 diseases: diab, ckd, htn\n",
        "    3 labs/vitals: hba1c, creat, bp\n",
        "    True influences:\n",
        "        diab_t -> ckd_{t+1}\n",
        "        htn_t  -> ckd_{t+1}\n",
        "        diab_t -> hba1c_{t+1}\n",
        "        ckd_t  -> creat_{t+1}\n",
        "    + self-transitions for all\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    rows = []\n",
        "    for pid in range(n_patients):\n",
        "        diab = rng.integers(0, K); ckd  = rng.integers(0, K); htn  = rng.integers(0, K)\n",
        "        hba1c = rng.integers(0, K); creat = rng.integers(0, K); bp = rng.integers(0, K)\n",
        "        for t in range(timesteps):\n",
        "            rows.append(dict(patient_id=pid, t=t, diab=diab, ckd=ckd, htn=htn, hba1c=hba1c, creat=creat, bp=bp))\n",
        "            diab_next = _clip_state(diab + rng.choice([-1,0,0,0,1]), K)\n",
        "            htn_next  = _clip_state(htn  + rng.choice([-1,0,0,0,1]), K)\n",
        "            ckd_shift = (1 if diab>0 else 0) + (1 if htn>0 else 0)\n",
        "            ckd_next  = _clip_state(ckd + rng.choice([-1,0,0,1]) + (1 if ckd_shift>0 and rng.random()<0.6 else 0), K)\n",
        "            hba1c_next = _clip_state(hba1c + (1 if diab>0 and rng.random()<0.7 else 0) + rng.choice([-1,0,0,1]), K)\n",
        "            creat_next = _clip_state(creat + (1 if ckd>0  and rng.random()<0.6 else 0) + rng.choice([-1,0,0,1]), K)\n",
        "            bp_next    = _clip_state(bp    + (1 if htn>0  and rng.random()<0.6 else 0) + rng.choice([-1,0,0,1]), K)\n",
        "            diab, ckd, htn, hba1c, creat, bp = diab_next, ckd_next, htn_next, hba1c_next, creat_next, bp_next\n",
        "    return pd.DataFrame(rows).sort_values([\"patient_id\",\"t\"]).reset_index(drop=True)\n",
        "\n",
        "# --------- Two-slice utilities ---------\n",
        "VARS = [\"diab\",\"ckd\",\"htn\",\"bp\",\"hba1c\",\"creat\"]\n",
        "\n",
        "def build_two_slice(df: pd.DataFrame, vars: List[str]) -> pd.DataFrame:\n",
        "    cur = df.copy(); cur[\"t1\"] = cur[\"t\"] + 1\n",
        "    cur = cur.rename(columns={v: f\"{v}_t\" for v in vars})[[\"patient_id\",\"t1\"] + [f\"{v}_t\" for v in vars]]\n",
        "    nxt = df.rename(columns={v: f\"{v}_t1\" for v in vars})[[\"patient_id\",\"t\"] + [f\"{v}_t1\" for v in vars]]\n",
        "    merged = pd.merge(cur, nxt, left_on=[\"patient_id\",\"t1\"], right_on=[\"patient_id\",\"t\"], how=\"inner\")\n",
        "    return merged.drop(columns=[\"t\",\"t1\"]).reset_index(drop=True)\n",
        "\n",
        "def self_edges(vars: List[str]):  return [(f\"{v}_t\", f\"{v}_t1\") for v in vars]\n",
        "def cross_edges(vars: List[str]): return [(f\"{u}_t\", f\"{v}_t1\") for u in vars for v in vars if u != v]\n",
        "\n",
        "# --------- Greedy BIC search ---------\n",
        "def score_model(structure: List[Tuple[str,str]], data: pd.DataFrame) -> float:\n",
        "    model = BayesianNetwork(structure)\n",
        "    model.add_nodes_from(list(data.columns))\n",
        "    model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
        "    return BicScore(data).score(model)\n",
        "\n",
        "def greedy_add_edges(data: pd.DataFrame, all_nodes: List[str], whitelist, start_edges, max_parents=2, max_iters=50):\n",
        "    current = list(start_edges)\n",
        "    best_score = score_model(current, data)\n",
        "    def parent_count(edges):\n",
        "        cnt = {n:0 for n in all_nodes}\n",
        "        for u,v in edges: cnt[v] += 1\n",
        "        return cnt\n",
        "    parents = parent_count(current)\n",
        "    candidates = list(set(whitelist) - set(current))\n",
        "    it = 0\n",
        "    while it < max_iters:\n",
        "        it += 1\n",
        "        best_delta, best_edge = 0.0, None\n",
        "        for e in candidates:\n",
        "            u,v = e\n",
        "            if parents[v] >= max_parents: continue\n",
        "            trial = current + [e]\n",
        "            try:\n",
        "                s = score_model(trial, data)\n",
        "            except Exception:\n",
        "                continue\n",
        "            delta = s - best_score\n",
        "            if delta > best_delta:\n",
        "                best_delta, best_edge = delta, e\n",
        "        if not best_edge or best_delta <= 0: break\n",
        "        current.append(best_edge); best_score += best_delta; parents[best_edge[1]] += 1; candidates.remove(best_edge)\n",
        "    return {\"edges\": current, \"bic\": best_score, \"iterations\": it}\n",
        "\n",
        "# --------- Fit + evaluate ---------\n",
        "def fit_bn(structure, train_df):\n",
        "    m = BayesianNetwork(structure)\n",
        "    m.add_nodes_from(list(train_df.columns))\n",
        "    m.fit(train_df, estimator=MaximumLikelihoodEstimator)\n",
        "    return m\n",
        "\n",
        "def evaluate_nextstep(model, test_df, vars):\n",
        "    infer = VariableElimination(model)\n",
        "    X_cols = [f\"{v}_t\" for v in vars]\n",
        "    out = {}\n",
        "    for v in vars:\n",
        "        y_true = test_df[f\"{v}_t1\"].values\n",
        "        preds = []\n",
        "        for i in range(len(test_df)):\n",
        "            evidence = {col: int(test_df.iloc[i][col]) for col in X_cols}\n",
        "            q = infer.query(variables=[f\"{v}_t1\"], evidence=evidence, show_progress=False)\n",
        "            preds.append(int(np.argmax(q.values)))\n",
        "        out[v] = {\"accuracy\": float((np.array(preds) == y_true).mean())}\n",
        "    return out\n",
        "\n",
        "def split_train_test(two_slice_df, test_frac=0.25, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(two_slice_df)); rng.shuffle(idx)\n",
        "    split = int(len(idx) * (1 - test_frac))\n",
        "    return two_slice_df.iloc[idx[:split]].reset_index(drop=True), two_slice_df.iloc[idx[split:]].reset_index(drop=True)\n",
        "\n",
        "# --------- Demo ---------\n",
        "def run_demo(n_patients=300, timesteps=20, seed=42, max_parents=2, test_frac=0.25):\n",
        "    df = generate_synthetic_comorbidity(n_patients=n_patients, timesteps=timesteps, random_state=seed)\n",
        "    two = build_two_slice(df, VARS)\n",
        "    train_df, test_df = split_train_test(two, test_frac=test_frac, seed=seed)\n",
        "\n",
        "    self_only = self_edges(VARS)\n",
        "    indep_bic = score_model(self_only, train_df)\n",
        "    indep_model = fit_bn(self_only, train_df)\n",
        "    indep_metrics = evaluate_nextstep(indep_model, test_df, VARS)\n",
        "\n",
        "    wl = self_only + cross_edges(VARS)\n",
        "    result = greedy_add_edges(train_df, list(train_df.columns), wl, self_only, max_parents=max_parents, max_iters=50)\n",
        "    infl_edges, infl_bic = result[\"edges\"], result[\"bic\"]\n",
        "    infl_model = fit_bn(infl_edges, train_df)\n",
        "    infl_metrics = evaluate_nextstep(infl_model, test_df, VARS)\n",
        "\n",
        "    return {\n",
        "        \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"config\": {\"n_patients\": n_patients, \"timesteps\": timesteps, \"seed\": seed,\n",
        "                   \"max_parents\": max_parents, \"test_frac\": test_frac},\n",
        "        \"independent\": {\"bic\": indep_bic, \"edges\": self_only, \"metrics\": indep_metrics},\n",
        "        \"influence\": {\"bic\": infl_bic, \"edges\": infl_edges, \"metrics\": infl_metrics}\n",
        "    }\n",
        "\n",
        "report = run_demo(n_patients=300, timesteps=20, seed=42, max_parents=2, test_frac=0.25)\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(\"Independent BIC:\", report[\"independent\"][\"bic\"])\n",
        "print(\"Influence   BIC:\", report[\"influence\"][\"bic\"])\n",
        "print(\"\\nEdges learned (influence model):\")\n",
        "for u,v in report[\"influence\"][\"edges\"]:\n",
        "    print(f\"  {u} -> {v}\")\n",
        "print(\"\\nPer-variable next-step accuracy (independent):\")\n",
        "for v, m in report[\"independent\"][\"metrics\"].items(): print(f\"  {v}: {m['accuracy']:.3f}\")\n",
        "print(\"Per-variable next-step accuracy (influence):\")\n",
        "for v, m in report[\"influence\"][\"metrics\"].items(): print(f\"  {v}: {m['accuracy']:.3f}\")\n",
        "\n",
        "with open(\"run_report.json\",\"w\") as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "print(\"\\nSaved: run_report.json\")\n"
      ]
    }
  ]
}